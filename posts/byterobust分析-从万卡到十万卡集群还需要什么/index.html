<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ByteRobust分析-从万卡到十万卡集群还需要什么 | Lei's</title><meta name=keywords content><meta name=description content="今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。
本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：
当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR
当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。
在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。
论文地址：Robust LLM Training Infrastructure at ByteDance
万卡训练，系统故障+人为代码故障是常态
Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下

显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。
进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。
ByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。
高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。

关键机制一：故障处理流水线，极大降低人工干预

Monitor 以秒级周期做轻量健康检查：

网络：NIC状态、端口抖动、switch down
GPU：驱动挂起、高温、GPU Lost、Xid错误
主机：内核panic、文件系统错误
训练：loss曲线、MFU下降、退出码等"><meta name=author content="Lei Wang"><link rel=canonical href=https://leinxx.github.io/posts/byterobust%E5%88%86%E6%9E%90-%E4%BB%8E%E4%B8%87%E5%8D%A1%E5%88%B0%E5%8D%81%E4%B8%87%E5%8D%A1%E9%9B%86%E7%BE%A4%E8%BF%98%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88/><link crossorigin=anonymous href=../../assets/css/stylesheet.a38206408aa4d2dee18741f1524de29b7c55a0c945d41aba76a7201c1e6ceeb4.css integrity="sha256-o4IGQIqk0t7hh0HxUk3im3xVoMlF1Bq6dqcgHB5s7rQ=" rel="preload stylesheet" as=style><link rel=icon href=https://leinxx.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://leinxx.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://leinxx.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://leinxx.github.io/apple-touch-icon.png><link rel=mask-icon href=https://leinxx.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://leinxx.github.io/posts/byterobust%E5%88%86%E6%9E%90-%E4%BB%8E%E4%B8%87%E5%8D%A1%E5%88%B0%E5%8D%81%E4%B8%87%E5%8D%A1%E9%9B%86%E7%BE%A4%E8%BF%98%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1},{left:"$",right:"$",display:!1}]})'></script><meta property="og:url" content="https://leinxx.github.io/posts/byterobust%E5%88%86%E6%9E%90-%E4%BB%8E%E4%B8%87%E5%8D%A1%E5%88%B0%E5%8D%81%E4%B8%87%E5%8D%A1%E9%9B%86%E7%BE%A4%E8%BF%98%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88/"><meta property="og:site_name" content="Lei's"><meta property="og:title" content="ByteRobust分析-从万卡到十万卡集群还需要什么"><meta property="og:description" content="今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。
本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：
当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR 当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。 在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。
论文地址：Robust LLM Training Infrastructure at ByteDance
万卡训练，系统故障+人为代码故障是常态 Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下
显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。
进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。
ByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。
高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。
关键机制一：故障处理流水线，极大降低人工干预 Monitor 以秒级周期做轻量健康检查： 网络：NIC状态、端口抖动、switch down GPU：驱动挂起、高温、GPU Lost、Xid错误 主机：内核panic、文件系统错误 训练：loss曲线、MFU下降、退出码等"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-12-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-10T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ByteRobust分析-从万卡到十万卡集群还需要什么"><meta name=twitter:description content="今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。
本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：
当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR
当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。
在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。
论文地址：Robust LLM Training Infrastructure at ByteDance
万卡训练，系统故障+人为代码故障是常态
Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下

显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。
进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。
ByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。
高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。

关键机制一：故障处理流水线，极大降低人工干预

Monitor 以秒级周期做轻量健康检查：

网络：NIC状态、端口抖动、switch down
GPU：驱动挂起、高温、GPU Lost、Xid错误
主机：内核panic、文件系统错误
训练：loss曲线、MFU下降、退出码等"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Welcome","item":"https://leinxx.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ByteRobust分析-从万卡到十万卡集群还需要什么","item":"https://leinxx.github.io/posts/byterobust%E5%88%86%E6%9E%90-%E4%BB%8E%E4%B8%87%E5%8D%A1%E5%88%B0%E5%8D%81%E4%B8%87%E5%8D%A1%E9%9B%86%E7%BE%A4%E8%BF%98%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ByteRobust分析-从万卡到十万卡集群还需要什么","name":"ByteRobust分析-从万卡到十万卡集群还需要什么","description":"今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。\n本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：\n当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR 当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。 在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。\n论文地址：Robust LLM Training Infrastructure at ByteDance\n万卡训练，系统故障+人为代码故障是常态 Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下\n显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。\n进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。\nByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。\n高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。\n关键机制一：故障处理流水线，极大降低人工干预 Monitor 以秒级周期做轻量健康检查： 网络：NIC状态、端口抖动、switch down GPU：驱动挂起、高温、GPU Lost、Xid错误 主机：内核panic、文件系统错误 训练：loss曲线、MFU下降、退出码等\n","keywords":[],"articleBody":"今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。\n本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：\n当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR 当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。 在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。\n论文地址：Robust LLM Training Infrastructure at ByteDance\n万卡训练，系统故障+人为代码故障是常态 Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下\n显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。\n进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。\nByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。\n高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。\n关键机制一：故障处理流水线，极大降低人工干预 Monitor 以秒级周期做轻量健康检查： 网络：NIC状态、端口抖动、switch down GPU：驱动挂起、高温、GPU Lost、Xid错误 主机：内核panic、文件系统错误 训练：loss曲线、MFU下降、退出码等\n结果对比基线，即仅依赖超时时间加监控告警，对于网络、GPU、主机等问题，检测时间从分钟级降到秒级。例如 switch down，检测时间从约 10min 降到 2s。\n快速重试 / 回滚：大部分显式故障止步于此 当错误比较明显时，比如典型的CUDA error、NCCL错误、典型OOM 等，直接执行标准恢复流程：驱逐故障机，拉起备机，checkpoint恢复。如果近期刚做过代码更新且错误集中在某一版本，则触发代码回滚，把代码也纳入自动化流程。\n在两个真实预训练任务中，显式故障的大头都由自动驱逐加自动重启解决 (AutoFT-ER)，占比分别为 73.1% 与 56.8%。\n停机诊断：小而专的测试脚本库 对于无法直接通过错误码判断的情况，特别是通信问题，Diagnoser 会按类型挑选测试脚本，比如：机内或机间 all-gather/all-to-all 测试，单机自检，DCGM EUD，文件系统读写压测，避免每次出事都要人工介入。\n双阶段重放：SDC 等极端情况的兜底方案 对于静默数据损坏 (SDC) 等极端情况，ByteRobust 会启动 Dual-Phase Replay。第一阶段按水平分组重放，第二阶段按垂直分组重放，两轮结果求交集后即可把坏机集合缩小到极少数节点，甚至单个GPU。只有1.23%的事件需要 Dual-Phase Replay，因此它是最后一层保险。\n关键机制二：数据驱动的故障定位与过度驱逐，实现快速故障定位 在大规模训练里，最复杂的故障类型之一是：训练没明显挂，但整体变慢，MFU 慢慢下降。GPU 看起来都在跑，日志也没 fatal error，这时就很难靠简单规则定位。ByteRobust的做法是：堆栈聚合与过度驱逐。\n堆栈聚合：找出可疑的并行组。当监控发现某个pipeline group的通信长时间异常，如RDMA流量为 0；某些 rank 的step time明显偏慢，通过分析异常进程，对堆栈文本做聚类分为正常和非正常两类，查找问题集中在哪些 TP/PP/DP 组，标记整个并行组为可疑。论文给了一个典型例子：反向通信挂起。大部分机器卡在 isend/irecv，一小撮机器卡在某个 all_gather 上，聚类之后很容易看到是同一PP组的 4 台机器有问题。\n过度驱逐，故意放弃精确到单机。确定可疑并行组之后，一整组踢掉，让温备用机器顶上，而不纠结到底是组里哪一台坏了。这样可大幅缩短定位加恢复时间，减轻人肉参与；代价是可能把一些没问题的机器一起踢掉，略损失资源利用率。系统还会每10秒做一次堆栈聚合和打分，对长期表现异常但不致命的并行组，累计5轮后得分最高的也会被驱逐，从而处理慢性硬件问题。\n关键机制三：高频 Checkpoint + 温备用 + 热更新实现快速重启 提升ETTR，减少端到端的故障时间，除了故障发现、故障隔离外，高效的故障处理同样重要。ByteRobust 有三件配套设计。\n温备用机器：预热好替补机器 字节维护了一组warm standby，即温备用机器池。根据历史数据对单机日故障率分布建模，取其P99的值反算standby数量。新加入的 standby 机器会预先完成自检、镜像下载、环境初始化，然后挂起等待。一旦某个并行组被驱逐，standby 机器直接接管身份，省去调度加初始化时间。在16384 GPU的评估实验中，温备用加热更新相比传统kill \u0026 requeue可以带来10.87× - 11.04× 的恢复加速。\n热更新：把改代码纳入训练流水线 ByteRobust 发现，大规模 LLM 训练里，人类改代码本身就是高频事件。于是，干脆把代码更新并入自动化流水线：紧急 bugfix：立即停下来，做in-place hot update，不重建 pod 环境；非关键优化：标记为延迟更新，在下一次故障恢复时顺带应用；超过默认时间窗口，比如 24h，仍未触发恢复，也会强制应用。这样的好处是：CI/CD 变成训练流程的一部分，而不是训练外的另一个流程。实现了比Requeue快了11倍。\n无损高频checkpoint 为配合过度驱逐，ByteRobust的checkpoint和备份策略提前考虑了整组消失的情况，并采用every-step checkpoint，通过异步 D2H 加序列化加 P2P 备份，把开销控制在几乎忽略不计（\u003c0.04s）。checkpoint 底层采用分层备份：GPU，本机 CPU 内存，本地 SSD。所有 shard 都按跨3D并行组备份。此外，论文还统计了HDFS等远端存储的错误：在三个月的训练里记录到1104次HDFS错误，因此ByteRobust尽量避免在故障恢复路径上依赖远端 FS，而是优先用本地或peer机器的备份来恢复。\n端到端效果：ETTR 与 MFU 双提升 显式故障大部分被自动容错解决，隐式故障中也有相当一部分通过堆栈聚合加过度驱逐解决，结合热备和热更新，绝大部分的错误可以无需人工干预。代码和数据相关的需要手工操作的错误基本可以完全被热更新覆盖。相比传统kill \u0026 requeue + 人工压测方案，平均事件解决时间缩短最高可达约 84.5%。\n三个月的dense job与一个月的MoE job，ETTR基本稳定在97%左右，滑动窗 (1 小时)ETTR虽有波动但保持在高位，说明故障虽然频繁，但恢复速度足够快。\n错误解决需要的耗时统计可以看到，隐性的错误（NaN value）由于诊断复杂，需要的时间远大于显性错误。文中提到隐性错误发生次数占总错误10%左右，因此隐性错误是当前带来最大损失的错误类型。\n十万卡的训练ETTR估算 当前ETTR为97.3%，平均故障时间2.6h，意味着平均恢复时间为\n2.6h *（1-97%）= 4.68min\n粗略估算十万卡的平均故障时间\n2.6h/10=15.6min\n则ETTR为\n1-(4.68/15.6)=70%\n由于集群规模扩大10倍，平均故障时间会降低10倍+，在恢复时长不变的情况下，ETTR预期会降低到70%左右。在十万卡集群达到97%的ETTR，需要平均恢复时长达到30s以内。\nAI Infra从有效训练时长的竞争转向计算正确性的竞争 随着可用性问题被ByteRobust等技术方案解决，系统的核心风险转移到了正确性上，核心是静默数据破坏（SDC）错误。SDC是指硬件在未报错的情况下输出了错误的计算结果（如 1+1=3）。和数据噪声不同，SDC会随机破坏系统的计算结果，期望非零，对梯度方向影响均值不可预期，相比数据噪声，SDC错误更难以被模型吸收，是一种触发概率不大，但是后果很严重的风险。Mercurial Cores论文提到发生SDC机器达千分之几。这对于训练任务是毁灭性的，因为它会污染模型参数，可能导致数周的训练成果作废，且极难回溯，从1W卡到10W卡规模，SDC的风险至少提升10倍，大幅限制了训练持续scaling up的能力。\n当前Nvidia并不在硬件层面保证结果正确性，其EUD诊断工具仅能正确检测70%的SDC错误。ByteRobuts在训练过程中，采用了loss曲线的异常检测， 利用机器学习模型实时监控训练的loss曲线。如果loss突然出现无法解释的剧烈震荡，系统首先怀疑SDC而非数据问题。此时，通过微回滚，退回N步并更换计算节点重试。如果重试后loss正常，则实锤了硬件SDC并隔离故障节点。在故障节点检测时，通过确定性miniGPT训练检测单机SDC错误，使用dual-replya方法检测跨机训练SDC错误。但是均需要停机，会带来高额overhead，需要更加高效和可靠的SDC错误检测和处理机制。Google，Meta等均采用了算前预检，基于算法的计算校验，过程校验，端到端结果校验等策略，但均需要在效果，软件复杂度，和开销之间trade off。\n计算正确性应成为昇腾云的竞争力构筑点 目前的GPU大多仅在存储单元（HBM、SRAM）上应用ECC，而运算单元（ALU、Tensor Core）往往缺乏保护。如果在Tensor Core内部引入轻量级的残差校验或奇偶校验。这会增加少量晶体管面积，但当前系统具备较高容错能力的情况下，收益是否有可能转正，需要重新评估。\n理论上，只要芯片具备完善的内部错误检测机制，确保任何运算错误都能立即触发中断，就可以将SDC转化为可被系统处理的显性崩溃，就可以在10万卡集群上地使用它。这种高灵敏度硬件 + 高弹性软件的组合将成为未来AI infra的标准路径：\n利用高弹集群管理系统将ETTR稳定在95%以上，解决效率问题。 利用芯片级自检和系统级审计消除SDC，解决可信问题。\n以云系统补硬件，降低AI硬件和基建的稳定性成本 为了维持高MTBF，AI芯片采用了极其严苛的分级筛选标准和昂贵的ECC显存，推高硬件成本。如果AI Infra系统能够容忍频繁的故障，我们可以大幅放宽对硬件质量的要求。训练规模越大，对硬件的质量要求越高。反之，对于在1W卡或者以内的训练，MTBF会降低，达成相同的ETTR意味着可以采用错误率更高的硬件，比如：\n放宽电压容限： 允许芯片在更不稳定的低电压下运行，增加错误率的同时大幅降低能耗。 降低良率标准： 接受部分核心有瑕疵的芯片，通过软件屏蔽坏点，大幅降低芯片制造成本。 激进的超频： 用高故障率换取高性能。\n在这种模式下，AI Infra的目标函数变为：\n最大化单位时间吞吐 * ETTR\n只要超频带来的吞吐量提升超过因故障率增加导致的ETTR损耗，这种策略就是正收益。从ByteRobust的实践来看，只要硬件故障能够被快速、明确地检测到（即显性故障），ByteRobust都能处理。系统最怕的不是频繁的崩溃，而是隐性的错误。如果算力资源的供给将不受限于精密制造的良率，而是可以利用廉价的、甚至部分有缺陷的芯片，可以大幅降低中小型训练集群的TCO成本。希望有大佬们分析一下是否有可行性。\n参考文献：\n“Mercurial Cores: Context-Aware Detection of Silent Data Corruption in High Performance Computing” (HotOS 2021, Google \u0026 ETH Zurich) ","wordCount":"252","inLanguage":"en","datePublished":"2025-12-10T00:00:00Z","dateModified":"2025-12-10T00:00:00Z","author":{"@type":"Person","name":"Lei Wang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://leinxx.github.io/posts/byterobust%E5%88%86%E6%9E%90-%E4%BB%8E%E4%B8%87%E5%8D%A1%E5%88%B0%E5%8D%81%E4%B8%87%E5%8D%A1%E9%9B%86%E7%BE%A4%E8%BF%98%E9%9C%80%E8%A6%81%E4%BB%80%E4%B9%88/"},"publisher":{"@type":"Organization","name":"Lei's","logo":{"@type":"ImageObject","url":"https://leinxx.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://leinxx.github.io/ accesskey=h title="Lei's (Alt + H)">Lei's</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://leinxx.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://leinxx.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://leinxx.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://leinxx.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://leinxx.github.io/posts/>Welcome</a></div><h1 class="post-title entry-hint-parent">ByteRobust分析-从万卡到十万卡集群还需要什么</h1><div class=post-meta><span title='2025-12-10 00:00:00 +0000 UTC'>December 10, 2025</span>&nbsp;·&nbsp;<span>2 min</span>&nbsp;·&nbsp;<span>Lei Wang</span></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%b8%87%e5%8d%a1%e8%ae%ad%e7%bb%83%e7%b3%bb%e7%bb%9f%e6%95%85%e9%9a%9c%e4%ba%ba%e4%b8%ba%e4%bb%a3%e7%a0%81%e6%95%85%e9%9a%9c%e6%98%af%e5%b8%b8%e6%80%81 aria-label=万卡训练，系统故障+人为代码故障是常态>万卡训练，系统故障+人为代码故障是常态</a></li><li><a href=#%e5%85%b3%e9%94%ae%e6%9c%ba%e5%88%b6%e4%b8%80%e6%95%85%e9%9a%9c%e5%a4%84%e7%90%86%e6%b5%81%e6%b0%b4%e7%ba%bf%e6%9e%81%e5%a4%a7%e9%99%8d%e4%bd%8e%e4%ba%ba%e5%b7%a5%e5%b9%b2%e9%a2%84 aria-label=关键机制一：故障处理流水线，极大降低人工干预>关键机制一：故障处理流水线，极大降低人工干预</a></li><li><a href=#%e5%85%b3%e9%94%ae%e6%9c%ba%e5%88%b6%e4%ba%8c%e6%95%b0%e6%8d%ae%e9%a9%b1%e5%8a%a8%e7%9a%84%e6%95%85%e9%9a%9c%e5%ae%9a%e4%bd%8d%e4%b8%8e%e8%bf%87%e5%ba%a6%e9%a9%b1%e9%80%90%e5%ae%9e%e7%8e%b0%e5%bf%ab%e9%80%9f%e6%95%85%e9%9a%9c%e5%ae%9a%e4%bd%8d aria-label=关键机制二：数据驱动的故障定位与过度驱逐，实现快速故障定位>关键机制二：数据驱动的故障定位与过度驱逐，实现快速故障定位</a></li><li><a href=#%e5%85%b3%e9%94%ae%e6%9c%ba%e5%88%b6%e4%b8%89%e9%ab%98%e9%a2%91-checkpoint--%e6%b8%a9%e5%a4%87%e7%94%a8--%e7%83%ad%e6%9b%b4%e6%96%b0%e5%ae%9e%e7%8e%b0%e5%bf%ab%e9%80%9f%e9%87%8d%e5%90%af aria-label="关键机制三：高频 Checkpoint + 温备用 + 热更新实现快速重启">关键机制三：高频 Checkpoint + 温备用 + 热更新实现快速重启</a></li><li><a href=#%e7%ab%af%e5%88%b0%e7%ab%af%e6%95%88%e6%9e%9cettr-%e4%b8%8e-mfu-%e5%8f%8c%e6%8f%90%e5%8d%87 aria-label="端到端效果：ETTR 与 MFU 双提升">端到端效果：ETTR 与 MFU 双提升</a></li><li><a href=#%e5%8d%81%e4%b8%87%e5%8d%a1%e7%9a%84%e8%ae%ad%e7%bb%83ettr%e4%bc%b0%e7%ae%97 aria-label=十万卡的训练ETTR估算>十万卡的训练ETTR估算</a></li><li><a href=#ai-infra%e4%bb%8e%e6%9c%89%e6%95%88%e8%ae%ad%e7%bb%83%e6%97%b6%e9%95%bf%e7%9a%84%e7%ab%9e%e4%ba%89%e8%bd%ac%e5%90%91%e8%ae%a1%e7%ae%97%e6%ad%a3%e7%a1%ae%e6%80%a7%e7%9a%84%e7%ab%9e%e4%ba%89 aria-label="AI Infra从有效训练时长的竞争转向计算正确性的竞争">AI Infra从有效训练时长的竞争转向计算正确性的竞争</a></li><li><a href=#%e8%ae%a1%e7%ae%97%e6%ad%a3%e7%a1%ae%e6%80%a7%e5%ba%94%e6%88%90%e4%b8%ba%e6%98%87%e8%85%be%e4%ba%91%e7%9a%84%e7%ab%9e%e4%ba%89%e5%8a%9b%e6%9e%84%e7%ad%91%e7%82%b9 aria-label=计算正确性应成为昇腾云的竞争力构筑点>计算正确性应成为昇腾云的竞争力构筑点</a></li><li><a href=#%e4%bb%a5%e4%ba%91%e7%b3%bb%e7%bb%9f%e8%a1%a5%e7%a1%ac%e4%bb%b6%e9%99%8d%e4%bd%8eai%e7%a1%ac%e4%bb%b6%e5%92%8c%e5%9f%ba%e5%bb%ba%e7%9a%84%e7%a8%b3%e5%ae%9a%e6%80%a7%e6%88%90%e6%9c%ac aria-label=以云系统补硬件，降低AI硬件和基建的稳定性成本>以云系统补硬件，降低AI硬件和基建的稳定性成本</a></li></ul></div></details></div><div class=post-content><p>今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。</p><p>本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：</p><p>当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR
当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。
在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。</p><p>论文地址：<a href=https://arxiv.org/pdf/2509.16293>Robust LLM Training Infrastructure at ByteDance</a></p><h2 id=万卡训练系统故障人为代码故障是常态>万卡训练，系统故障+人为代码故障是常态<a hidden class=anchor aria-hidden=true href=#万卡训练系统故障人为代码故障是常态>#</a></h2><p>Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下</p><img src=byterobust-training-incidents-stats.png width=50%><p>显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。</p><p>进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。</p><p>ByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。</p><p>高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。</p><img src=byterobust_workflow.png width=100%><h2 id=关键机制一故障处理流水线极大降低人工干预>关键机制一：故障处理流水线，极大降低人工干预<a hidden class=anchor aria-hidden=true href=#关键机制一故障处理流水线极大降低人工干预>#</a></h2><ol><li>Monitor 以秒级周期做轻量健康检查：</li></ol><p>网络：NIC状态、端口抖动、switch down
GPU：驱动挂起、高温、GPU Lost、Xid错误
主机：内核panic、文件系统错误
训练：loss曲线、MFU下降、退出码等</p><p>结果对比基线，即仅依赖超时时间加监控告警，对于网络、GPU、主机等问题，检测时间从分钟级降到秒级。例如 switch down，检测时间从约 10min 降到 2s。</p><ol start=2><li>快速重试 / 回滚：大部分显式故障止步于此</li></ol><p>当错误比较明显时，比如典型的CUDA error、NCCL错误、典型OOM 等，直接执行标准恢复流程：驱逐故障机，拉起备机，checkpoint恢复。如果近期刚做过代码更新且错误集中在某一版本，则触发代码回滚，把代码也纳入自动化流程。</p><p>在两个真实预训练任务中，显式故障的大头都由自动驱逐加自动重启解决 (AutoFT-ER)，占比分别为 73.1% 与 56.8%。</p><ol start=3><li>停机诊断：小而专的测试脚本库</li></ol><p>对于无法直接通过错误码判断的情况，特别是通信问题，Diagnoser 会按类型挑选测试脚本，比如：机内或机间 all-gather/all-to-all 测试，单机自检，DCGM EUD，文件系统读写压测，避免每次出事都要人工介入。</p><ol start=4><li>双阶段重放：SDC 等极端情况的兜底方案</li></ol><p>对于静默数据损坏 (SDC) 等极端情况，ByteRobust 会启动 Dual-Phase Replay。第一阶段按水平分组重放，第二阶段按垂直分组重放，两轮结果求交集后即可把坏机集合缩小到极少数节点，甚至单个GPU。只有1.23%的事件需要 Dual-Phase Replay，因此它是最后一层保险。</p><p> </p><h2 id=关键机制二数据驱动的故障定位与过度驱逐实现快速故障定位>关键机制二：数据驱动的故障定位与过度驱逐，实现快速故障定位<a hidden class=anchor aria-hidden=true href=#关键机制二数据驱动的故障定位与过度驱逐实现快速故障定位>#</a></h2><p>在大规模训练里，最复杂的故障类型之一是：训练没明显挂，但整体变慢，MFU 慢慢下降。GPU 看起来都在跑，日志也没 fatal error，这时就很难靠简单规则定位。ByteRobust的做法是：堆栈聚合与过度驱逐。</p><p>堆栈聚合：找出可疑的并行组。当监控发现某个pipeline group的通信长时间异常，如RDMA流量为 0；某些 rank 的step time明显偏慢，通过分析异常进程，对堆栈文本做聚类分为正常和非正常两类，查找问题集中在哪些 TP/PP/DP 组，标记整个并行组为可疑。论文给了一个典型例子：反向通信挂起。大部分机器卡在 isend/irecv，一小撮机器卡在某个 all_gather 上，聚类之后很容易看到是同一PP组的 4 台机器有问题。</p><p>过度驱逐，故意放弃精确到单机。确定可疑并行组之后，一整组踢掉，让温备用机器顶上，而不纠结到底是组里哪一台坏了。这样可大幅缩短定位加恢复时间，减轻人肉参与；代价是可能把一些没问题的机器一起踢掉，略损失资源利用率。系统还会每10秒做一次堆栈聚合和打分，对长期表现异常但不致命的并行组，累计5轮后得分最高的也会被驱逐，从而处理慢性硬件问题。</p><h2 id=关键机制三高频-checkpoint--温备用--热更新实现快速重启>关键机制三：高频 Checkpoint + 温备用 + 热更新实现快速重启<a hidden class=anchor aria-hidden=true href=#关键机制三高频-checkpoint--温备用--热更新实现快速重启>#</a></h2><p>提升ETTR，减少端到端的故障时间，除了故障发现、故障隔离外，高效的故障处理同样重要。ByteRobust 有三件配套设计。</p><ol><li>温备用机器：预热好替补机器</li></ol><p>字节维护了一组warm standby，即温备用机器池。根据历史数据对单机日故障率分布建模，取其P99的值反算standby数量。新加入的 standby 机器会预先完成自检、镜像下载、环境初始化，然后挂起等待。一旦某个并行组被驱逐，standby 机器直接接管身份，省去调度加初始化时间。在16384 GPU的评估实验中，温备用加热更新相比传统kill & requeue可以带来10.87× - 11.04× 的恢复加速。</p><ol start=2><li>热更新：把改代码纳入训练流水线</li></ol><p>ByteRobust 发现，大规模 LLM 训练里，人类改代码本身就是高频事件。于是，干脆把代码更新并入自动化流水线：紧急 bugfix：立即停下来，做in-place hot update，不重建 pod 环境；非关键优化：标记为延迟更新，在下一次故障恢复时顺带应用；超过默认时间窗口，比如 24h，仍未触发恢复，也会强制应用。这样的好处是：CI/CD 变成训练流程的一部分，而不是训练外的另一个流程。实现了比Requeue快了11倍。</p><ol start=3><li>无损高频checkpoint</li></ol><p>为配合过度驱逐，ByteRobust的checkpoint和备份策略提前考虑了整组消失的情况，并采用every-step checkpoint，通过异步 D2H 加序列化加 P2P 备份，把开销控制在几乎忽略不计（&lt;0.04s）。checkpoint 底层采用分层备份：GPU，本机 CPU 内存，本地 SSD。所有 shard 都按跨3D并行组备份。此外，论文还统计了HDFS等远端存储的错误：在三个月的训练里记录到1104次HDFS错误，因此ByteRobust尽量避免在故障恢复路径上依赖远端 FS，而是优先用本地或peer机器的备份来恢复。</p><h2 id=端到端效果ettr-与-mfu-双提升>端到端效果：ETTR 与 MFU 双提升<a hidden class=anchor aria-hidden=true href=#端到端效果ettr-与-mfu-双提升>#</a></h2><p>显式故障大部分被自动容错解决，隐式故障中也有相当一部分通过堆栈聚合加过度驱逐解决，结合热备和热更新，绝大部分的错误可以无需人工干预。代码和数据相关的需要手工操作的错误基本可以完全被热更新覆盖。相比传统kill & requeue + 人工压测方案，平均事件解决时间缩短最高可达约 84.5%。</p><p>三个月的dense job与一个月的MoE job，ETTR基本稳定在97%左右，滑动窗 (1 小时)ETTR虽有波动但保持在高位，说明故障虽然频繁，但恢复速度足够快。</p><p>错误解决需要的耗时统计可以看到，隐性的错误（NaN value）由于诊断复杂，需要的时间远大于显性错误。文中提到隐性错误发生次数占总错误10%左右，因此隐性错误是当前带来最大损失的错误类型。</p><h2 id=十万卡的训练ettr估算>十万卡的训练ETTR估算<a hidden class=anchor aria-hidden=true href=#十万卡的训练ettr估算>#</a></h2><p>当前ETTR为97.3%，平均故障时间2.6h，意味着平均恢复时间为</p><p>2.6h *（1-97%）= 4.68min</p><p>粗略估算十万卡的平均故障时间</p><p>2.6h/10=15.6min</p><p>则ETTR为</p><p>1-(4.68/15.6)=70%</p><p>由于集群规模扩大10倍，平均故障时间会降低10倍+，在恢复时长不变的情况下，ETTR预期会降低到70%左右。在十万卡集群达到97%的ETTR，需要平均恢复时长达到30s以内。</p><h2 id=ai-infra从有效训练时长的竞争转向计算正确性的竞争>AI Infra从有效训练时长的竞争转向计算正确性的竞争<a hidden class=anchor aria-hidden=true href=#ai-infra从有效训练时长的竞争转向计算正确性的竞争>#</a></h2><p>随着可用性问题被ByteRobust等技术方案解决，系统的核心风险转移到了正确性上，核心是静默数据破坏（SDC）错误。SDC是指硬件在未报错的情况下输出了错误的计算结果（如 1+1=3）。和数据噪声不同，SDC会随机破坏系统的计算结果，期望非零，对梯度方向影响均值不可预期，相比数据噪声，SDC错误更难以被模型吸收，是一种触发概率不大，但是后果很严重的风险。Mercurial Cores论文提到发生SDC机器达千分之几。这对于训练任务是毁灭性的，因为它会污染模型参数，可能导致数周的训练成果作废，且极难回溯，从1W卡到10W卡规模，SDC的风险至少提升10倍，大幅限制了训练持续scaling up的能力。</p><p>当前Nvidia并不在硬件层面保证结果正确性，其EUD诊断工具仅能正确检测70%的SDC错误。ByteRobuts在训练过程中，采用了loss曲线的异常检测， 利用机器学习模型实时监控训练的loss曲线。如果loss突然出现无法解释的剧烈震荡，系统首先怀疑SDC而非数据问题。此时，通过微回滚，退回N步并更换计算节点重试。如果重试后loss正常，则实锤了硬件SDC并隔离故障节点。在故障节点检测时，通过确定性miniGPT训练检测单机SDC错误，使用dual-replya方法检测跨机训练SDC错误。但是均需要停机，会带来高额overhead，需要更加高效和可靠的SDC错误检测和处理机制。Google，Meta等均采用了算前预检，基于算法的计算校验，过程校验，端到端结果校验等策略，但均需要在效果，软件复杂度，和开销之间trade off。</p><h2 id=计算正确性应成为昇腾云的竞争力构筑点>计算正确性应成为昇腾云的竞争力构筑点<a hidden class=anchor aria-hidden=true href=#计算正确性应成为昇腾云的竞争力构筑点>#</a></h2><p>目前的GPU大多仅在存储单元（HBM、SRAM）上应用ECC，而运算单元（ALU、Tensor Core）往往缺乏保护。如果在Tensor Core内部引入轻量级的残差校验或奇偶校验。这会增加少量晶体管面积，但当前系统具备较高容错能力的情况下，收益是否有可能转正，需要重新评估。</p><p>理论上，只要芯片具备完善的内部错误检测机制，确保任何运算错误都能立即触发中断，就可以将SDC转化为可被系统处理的显性崩溃，就可以在10万卡集群上地使用它。这种高灵敏度硬件 + 高弹性软件的组合将成为未来AI infra的标准路径：</p><p>利用高弹集群管理系统将ETTR稳定在95%以上，解决效率问题。
利用芯片级自检和系统级审计消除SDC，解决可信问题。</p><h2 id=以云系统补硬件降低ai硬件和基建的稳定性成本>以云系统补硬件，降低AI硬件和基建的稳定性成本<a hidden class=anchor aria-hidden=true href=#以云系统补硬件降低ai硬件和基建的稳定性成本>#</a></h2><p>为了维持高MTBF，AI芯片采用了极其严苛的分级筛选标准和昂贵的ECC显存，推高硬件成本。如果AI Infra系统能够容忍频繁的故障，我们可以大幅放宽对硬件质量的要求。训练规模越大，对硬件的质量要求越高。反之，对于在1W卡或者以内的训练，MTBF会降低，达成相同的ETTR意味着可以采用错误率更高的硬件，比如：</p><p>放宽电压容限： 允许芯片在更不稳定的低电压下运行，增加错误率的同时大幅降低能耗。
降低良率标准： 接受部分核心有瑕疵的芯片，通过软件屏蔽坏点，大幅降低芯片制造成本。
激进的超频： 用高故障率换取高性能。</p><p>在这种模式下，AI Infra的目标函数变为：</p><p>最大化单位时间吞吐 * ETTR</p><p>只要超频带来的吞吐量提升超过因故障率增加导致的ETTR损耗，这种策略就是正收益。从ByteRobust的实践来看，只要硬件故障能够被快速、明确地检测到（即显性故障），ByteRobust都能处理。系统最怕的不是频繁的崩溃，而是隐性的错误。如果算力资源的供给将不受限于精密制造的良率，而是可以利用廉价的、甚至部分有缺陷的芯片，可以大幅降低中小型训练集群的TCO成本。希望有大佬们分析一下是否有可行性。</p><p>参考文献：</p><p>&ldquo;Mercurial Cores: Context-Aware Detection of Silent Data Corruption in High Performance Computing&rdquo; (HotOS 2021, Google & ETH Zurich) </p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on x" href="https://x.com/intent/tweet/?text=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88&amp;url=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f&amp;title=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88&amp;summary=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88&amp;source=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f&title=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on whatsapp" href="https://api.whatsapp.com/send?text=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88%20-%20https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on telegram" href="https://telegram.me/share/url?text=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88&amp;url=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ByteRobust分析-从万卡到十万卡集群还需要什么 on ycombinator" href="https://news.ycombinator.com/submitlink?t=ByteRobust%e5%88%86%e6%9e%90-%e4%bb%8e%e4%b8%87%e5%8d%a1%e5%88%b0%e5%8d%81%e4%b8%87%e5%8d%a1%e9%9b%86%e7%be%a4%e8%bf%98%e9%9c%80%e8%a6%81%e4%bb%80%e4%b9%88&u=https%3a%2f%2fleinxx.github.io%2fposts%2fbyterobust%25E5%2588%2586%25E6%259E%2590-%25E4%25BB%258E%25E4%25B8%2587%25E5%258D%25A1%25E5%2588%25B0%25E5%258D%2581%25E4%25B8%2587%25E5%258D%25A1%25E9%259B%2586%25E7%25BE%25A4%25E8%25BF%2598%25E9%259C%2580%25E8%25A6%2581%25E4%25BB%2580%25E4%25B9%2588%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://leinxx.github.io/>Lei's</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>