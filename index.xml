<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Lei's Log</title><link>https://leinxx.github.io/</link><description>Recent content on Lei's Log</description><generator>Hugo -- 0.152.2</generator><language>en-us</language><lastBuildDate>Sat, 20 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://leinxx.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>2025-12-10-ByteRobust洞察分析-从万卡到十万卡集群还需要什么</title><link>https://leinxx.github.io/2025-12-10-byterobuts/</link><pubDate>Sat, 20 Dec 2025 00:00:00 +0000</pubDate><guid>https://leinxx.github.io/2025-12-10-byterobuts/</guid><description>&lt;p&gt;今年 10 月，字节跳动联合香港大学在 ACM 操作系统顶会 SOSP 发布了论文 Robust LLM Training Infrastructure at ByteDance，系统名为 ByteRobust。这套系统已经在字节的生产级GPU平台上部署了一年多，覆盖20万张GPU的集群，在一次持续 3个月、使用 9600 张 H100 GPU的大模型预训练任务中，实现了97% 的有效训练时间比率(ETTR)，刷新业界SOTA。&lt;/p&gt;
&lt;p&gt;本文尝试对ByteRobust做一次工程视角的技术解读，并提出以下几个观点：&lt;/p&gt;
&lt;p&gt;当前预估将ByteRobust扩展到10W卡级别，可以达到70%的ETTR
当系统具备微秒级别的快恢能力，单硬件组件的平均无故障时间（MTBF）将不再是瓶颈。云上弹性系统能力可以补充硬件可靠性的不足，从而减少AI集群的TCO。
在训练系统扩展到10万卡规模时，静默数据错误（SDC）风险将成为主要矛盾，AI Infra将从有效训练时长的竞争转向计算正确性的竞争。计算正确性应成为昇腾云的竞争力构筑点。&lt;/p&gt;
&lt;p&gt;论文地址：&lt;a href="https://arxiv.org/pdf/2509.16293"&gt;Robust LLM Training Infrastructure at ByteDance&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="万卡训练系统故障人为代码故障是常态"&gt;万卡训练，系统故障+人为代码故障是常态&lt;/h2&gt;
&lt;p&gt;Meta报告过，在 16000块GPU训练大模型时，硬件故障平均每2.78小时出现一次。像CUDA error、NCCL timeout、NaN、job hang，这些在小规模集群里偶尔遇到的问题，在万卡集群里会高频发生。传统做法大概是这样一条链路：故障检测，训练终止，看日志，找运维，换机器，重跑。大量闲置时间。字节在生产环境统计了77万+个训练任务的事件数据，并按显式故障、隐式故障、手工重启分类，结果大致如下&lt;/p&gt;
&lt;img src="byterobust-training-incidents-stats.png" width="50%"&gt;
&lt;p&gt;显式故障中 CUDA Error 约占36.1%，CPU Overload 约11%，CPU OOM 约10%；隐式故障如 Job hang约 9.9%；手工重启，比如代码或数据调整，约17.3%。可以直观看到：显式故障只是问题的一部分，隐式故障和人工操作也在大量吞噬有效训练时间。&lt;/p&gt;
&lt;p&gt;进一步统计故障耗时，论文把无效时间拆成检测时间、定位时间、failover 时间。显式故障的 failover 时间较长，隐式故障如 job hang、MFU下降，在检测和定位阶段耗时巨大。整体看，故障 - 停机 - 人肉诊断 - 恢复 这条链路的开销，从几十分钟到几小时不等，随着训练规模增长会成倍放大。&lt;/p&gt;
&lt;p&gt;ByteRobust的核心观点在于导致ETTR低下的根本原因并非错误的发生频率，而是错误处理流程的低效。绝大多数故障（超过90%）的影响时长在理论上可以被压缩至秒级，而无需经历传统调度器冗长的“检测-驱逐-重启”循环。把原本依赖人工SRE的故障处理流程，收敛成一条自动化流水线，用最低成本先把机器从不可训练拉会继续训练，延后根因分析，最大化 ETTR。&lt;/p&gt;
&lt;p&gt;高效的执行这套高效的自动化处理策略，还需要快速故障定位，以及快速恢复能力，这三点构成了文章的三个核心机制。下面是完整的处理流程图。&lt;/p&gt;
&lt;img src="byterobust_workflow.png" width="100%"&gt;
&lt;h2 id="关键机制一故障处理流水线极大降低人工干预"&gt;关键机制一：故障处理流水线，极大降低人工干预&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Monitor 以秒级周期做轻量健康检查：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;网络：NIC状态、端口抖动、switch down
GPU：驱动挂起、高温、GPU Lost、Xid错误
主机：内核panic、文件系统错误
训练：loss曲线、MFU下降、退出码等&lt;/p&gt;</description></item><item><title>Diffusion Models Explained</title><link>https://leinxx.github.io/first-post/</link><pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate><guid>https://leinxx.github.io/first-post/</guid><description>&lt;img src="https://leinxx.github.io/first-post/test.jpg" alt="Diffusion model" width="80%"&gt;
&lt;p&gt;Your content&amp;hellip;&lt;/p&gt;
&lt;h2 id="equation-rendering"&gt;Equation Rendering&lt;/h2&gt;
&lt;p&gt;We can write:&lt;/p&gt;
&lt;p&gt;$$
x_t = \sqrt{\alpha_t}x_0 + \sqrt{1-\alpha_t}z
$$&lt;/p&gt;</description></item></channel></rss>